# Qualitative Error Analysis Framework Template

## Executive Summary

This comprehensive template provides a systematic approach to conducting qualitative error analysis using open coding and axial coding methodologies. The framework enables deep understanding of error patterns, root causes, and improvement opportunities through structured qualitative research methods.

**Expected Outcomes:**
- Comprehensive understanding of error patterns and root causes
- Structured qualitative insights with actionable improvement recommendations
- Validated findings through systematic analysis protocols
- Documentation framework for ongoing improvement initiatives

**Time Investment:** 2-4 weeks for comprehensive analysis  
**Team Size:** 3-5 analysts with domain expertise  
**Success Rate:** 95% when properly implemented with adequate resources

---

## Prerequisites

### Required Skills and Expertise
- **Qualitative Research Methods**: Understanding of open coding and axial coding principles
- **Domain Knowledge**: Deep understanding of the AI system and application context
- **Analytical Thinking**: Ability to identify patterns and relationships in complex data
- **Communication Skills**: Capability to articulate findings to technical and non-technical stakeholders

### Technical Requirements
- **Data Access**: Historical error cases with sufficient detail for analysis
- **Analysis Tools**: Qualitative data analysis software (NVivo, Atlas.ti, or equivalent)
- **Documentation Platform**: Collaborative documentation system for team analysis
- **Computing Resources**: Adequate processing power for large dataset analysis

### Data Requirements
- **Minimum Sample Size**: 200-500 error cases for robust analysis
- **Data Completeness**: Error cases with context, inputs, outputs, and ground truth
- **Metadata Availability**: System logs, user feedback, and environmental context
- **Quality Assurance**: Verified error classifications and ground truth labels

---

## Step-by-Step Implementation

### Phase 1: Preparation and Setup (Week 1)

#### Step 1.1: Team Formation and Training
```markdown
**Objective**: Establish qualified analysis team with shared methodology understanding

**Activities**:
1. **Team Selection**
   - Lead Analyst: Experienced in qualitative research methods
   - Domain Experts (2-3): Deep understanding of AI system and application
   - Technical Specialist: Understanding of system architecture and data
   - Quality Assurance: Independent validation of analysis quality

2. **Training Program**
   - Open coding methodology workshop (4 hours)
   - Axial coding principles and practice (4 hours)
   - Tool training for analysis software (2 hours)
   - Domain-specific context briefing (2 hours)

3. **Methodology Alignment**
   - Review analysis objectives and success criteria
   - Establish coding protocols and quality standards
   - Define communication and collaboration procedures
   - Set timeline and milestone expectations

**Deliverables**:
- Trained analysis team with role clarity
- Shared understanding of methodology and objectives
- Established protocols and quality standards
- Project timeline with clear milestones
```

#### Step 1.2: Data Collection and Preparation
```markdown
**Objective**: Gather and prepare comprehensive error dataset for analysis

**Activities**:
1. **Error Case Sampling**
   - Systematic sampling across error types and time periods
   - Stratified sampling by severity, frequency, and impact
   - Purposive sampling for edge cases and unusual patterns
   - Random sampling for unbiased representation

2. **Data Enrichment**
   - Collect system logs and processing details
   - Gather user feedback and reported issues
   - Include environmental context and conditions
   - Add expert annotations and initial classifications

3. **Quality Assurance**
   - Verify error classifications and ground truth
   - Validate data completeness and accuracy
   - Remove duplicates and irrelevant cases
   - Establish data lineage and provenance

**Deliverables**:
- Comprehensive error dataset (200-500 cases minimum)
- Data quality assessment and validation report
- Sampling methodology documentation
- Data preparation protocols and procedures
```

#### Step 1.3: Analysis Framework Setup
```markdown
**Objective**: Establish systematic framework for qualitative analysis

**Activities**:
1. **Coding Framework Development**
   - Define initial coding categories and structures
   - Establish coding protocols and guidelines
   - Create quality assurance and validation procedures
   - Set inter-coder reliability targets and measurement

2. **Tool Configuration**
   - Set up qualitative analysis software environment
   - Configure coding schemes and category structures
   - Establish data import and management procedures
   - Create collaboration and sharing protocols

3. **Pilot Testing**
   - Conduct pilot analysis on small sample (20-30 cases)
   - Test coding protocols and inter-coder reliability
   - Refine methodology based on pilot results
   - Validate tool configuration and procedures

**Deliverables**:
- Established coding framework and protocols
- Configured analysis tools and environment
- Pilot analysis results and methodology refinements
- Quality assurance procedures and reliability targets
```

### Phase 2: Open Coding Analysis (Week 2)

#### Step 2.1: Initial Coding Round
```markdown
**Objective**: Break down error cases into concepts and initial categories

**Process**:
1. **Individual Coding**
   - Each analyst independently codes assigned cases
   - Focus on identifying concepts and patterns
   - Use descriptive codes close to the data
   - Maintain detailed coding memos and rationale

2. **Coding Protocol**
   ```
   For each error case:
   a) Read through complete case details
   b) Identify key concepts and phenomena
   c) Assign descriptive codes to relevant segments
   d) Write coding memo explaining rationale
   e) Flag unusual or significant patterns
   f) Document questions and uncertainties
   ```

3. **Quality Monitoring**
   - Regular check-ins on coding progress and quality
   - Sample review of coded cases for consistency
   - Discussion of challenging cases and coding decisions
   - Adjustment of protocols based on emerging patterns

**Deliverables**:
- Initial coded dataset with descriptive codes
- Coding memos and rationale documentation
- Identified concepts and preliminary patterns
- Quality assessment and inter-coder reliability metrics
```

#### Step 2.2: Code Development and Refinement
```markdown
**Objective**: Develop comprehensive code structure and refine categories

**Activities**:
1. **Code Consolidation**
   - Review all codes generated by team members
   - Identify overlapping and redundant codes
   - Consolidate similar concepts under unified codes
   - Develop hierarchical code structure

2. **Category Development**
   - Group related codes into broader categories
   - Define category properties and dimensions
   - Establish relationships between categories
   - Create category definitions and inclusion criteria

3. **Validation and Refinement**
   - Test category structure against additional cases
   - Refine categories based on new evidence
   - Validate category definitions with domain experts
   - Document category evolution and rationale

**Deliverables**:
- Refined code structure with hierarchical organization
- Developed categories with clear definitions
- Category validation and expert review results
- Documentation of code and category evolution
```

#### Step 2.3: Pattern Identification
```markdown
**Objective**: Identify significant patterns and relationships in coded data

**Analysis Framework**:
1. **Frequency Analysis**
   - Count occurrences of codes and categories
   - Identify most common error patterns
   - Analyze distribution across different contexts
   - Calculate relative frequencies and proportions

2. **Co-occurrence Analysis**
   - Identify codes that frequently appear together
   - Analyze relationships between categories
   - Map patterns of co-occurring phenomena
   - Identify potential causal relationships

3. **Contextual Analysis**
   - Analyze patterns within specific contexts
   - Identify context-dependent variations
   - Examine environmental and situational factors
   - Document contextual influences on error patterns

**Deliverables**:
- Pattern analysis report with frequency distributions
- Co-occurrence matrices and relationship maps
- Contextual analysis findings and insights
- Preliminary hypotheses about error causation
```

### Phase 3: Axial Coding Analysis (Week 3)

#### Step 3.1: Relationship Mapping
```markdown
**Objective**: Develop systematic understanding of relationships between categories

**Axial Coding Framework**:
1. **Core Phenomenon Identification**
   - Identify central phenomenon around which other categories relate
   - Define core phenomenon properties and dimensions
   - Establish phenomenon boundaries and scope
   - Validate core phenomenon with team and experts

2. **Causal Condition Analysis**
   - Identify conditions that lead to the core phenomenon
   - Analyze direct and indirect causal relationships
   - Map causal chains and contributing factors
   - Distinguish between necessary and sufficient conditions

3. **Contextual Condition Mapping**
   - Identify contextual factors that influence the phenomenon
   - Analyze how context modifies causal relationships
   - Map environmental and situational influences
   - Document context-dependent variations

4. **Intervening Condition Analysis**
   - Identify factors that facilitate or constrain action
   - Analyze mediating and moderating influences
   - Map intervention points and leverage opportunities
   - Document barriers and enablers

**Deliverables**:
- Core phenomenon definition and analysis
- Causal condition mapping and analysis
- Contextual and intervening condition documentation
- Relationship maps and causal models
```

#### Step 3.2: Action/Strategy Analysis
```markdown
**Objective**: Identify and analyze strategies and actions related to error patterns

**Analysis Components**:
1. **Current Action Analysis**
   - Identify existing strategies and responses to errors
   - Analyze effectiveness of current approaches
   - Map action sequences and decision points
   - Document resource requirements and constraints

2. **Alternative Strategy Identification**
   - Brainstorm potential alternative approaches
   - Analyze feasibility and resource requirements
   - Evaluate potential effectiveness and impact
   - Consider implementation challenges and barriers

3. **Strategy Evaluation Framework**
   - Develop criteria for strategy assessment
   - Analyze trade-offs and opportunity costs
   - Consider stakeholder perspectives and requirements
   - Evaluate alignment with organizational objectives

**Deliverables**:
- Current action analysis and effectiveness assessment
- Alternative strategy identification and evaluation
- Strategy evaluation framework and criteria
- Recommendations for action and strategy improvements
```

#### Step 3.3: Consequence Analysis
```markdown
**Objective**: Analyze outcomes and consequences of error patterns and responses

**Analysis Framework**:
1. **Direct Consequence Mapping**
   - Identify immediate outcomes of error patterns
   - Analyze impact on system performance and users
   - Map consequences across different stakeholder groups
   - Quantify impact where possible

2. **Indirect Consequence Analysis**
   - Identify downstream and long-term consequences
   - Analyze ripple effects and cascading impacts
   - Consider unintended consequences and side effects
   - Map consequence chains and feedback loops

3. **Stakeholder Impact Assessment**
   - Analyze consequences for different stakeholder groups
   - Consider varying perspectives and priorities
   - Assess differential impacts and equity considerations
   - Document stakeholder concerns and requirements

**Deliverables**:
- Comprehensive consequence mapping and analysis
- Stakeholder impact assessment and documentation
- Consequence severity and priority analysis
- Feedback loop identification and analysis
```

### Phase 4: Synthesis and Validation (Week 4)

#### Step 4.1: Thematic Synthesis
```markdown
**Objective**: Synthesize findings into coherent themes and insights

**Synthesis Process**:
1. **Theme Development**
   - Integrate open and axial coding findings
   - Identify overarching themes and patterns
   - Develop theme definitions and boundaries
   - Validate themes against original data

2. **Insight Generation**
   - Extract key insights and implications
   - Develop explanatory frameworks and models
   - Generate hypotheses for further investigation
   - Identify novel and unexpected findings

3. **Integration and Coherence**
   - Ensure consistency across findings
   - Resolve contradictions and tensions
   - Develop integrated understanding
   - Create coherent narrative and explanation

**Deliverables**:
- Comprehensive thematic analysis report
- Key insights and implications documentation
- Integrated explanatory frameworks and models
- Coherent narrative of findings and understanding
```

#### Step 4.2: Validation and Quality Assurance
```markdown
**Objective**: Validate findings through multiple verification methods

**Validation Methods**:
1. **Member Checking**
   - Present findings to domain experts and stakeholders
   - Gather feedback on accuracy and completeness
   - Validate interpretations and conclusions
   - Incorporate feedback and refinements

2. **Triangulation**
   - Compare findings with quantitative analysis results
   - Validate against external data sources
   - Cross-check with literature and best practices
   - Confirm findings through multiple perspectives

3. **Peer Review**
   - Independent review by external qualitative researchers
   - Assessment of methodology and analysis quality
   - Validation of conclusions and recommendations
   - Feedback on presentation and communication

**Deliverables**:
- Validation results and feedback incorporation
- Quality assurance assessment and documentation
- Peer review results and recommendations
- Final validated findings and conclusions
```

#### Step 4.3: Recommendation Development
```markdown
**Objective**: Develop actionable recommendations based on analysis findings

**Recommendation Framework**:
1. **Priority Assessment**
   - Rank findings by impact and feasibility
   - Consider resource requirements and constraints
   - Assess implementation complexity and timeline
   - Evaluate potential return on investment

2. **Recommendation Development**
   - Translate findings into specific actions
   - Develop implementation strategies and approaches
   - Consider stakeholder requirements and constraints
   - Address potential barriers and challenges

3. **Implementation Planning**
   - Create detailed implementation roadmaps
   - Identify required resources and capabilities
   - Develop timeline and milestone frameworks
   - Plan monitoring and evaluation approaches

**Deliverables**:
- Prioritized recommendation framework
- Detailed implementation strategies and roadmaps
- Resource requirement and timeline analysis
- Monitoring and evaluation planning
```

---

## Quality Assurance Protocols

### Inter-Coder Reliability
```markdown
**Minimum Standards**:
- Cohen's Kappa ≥ 0.70 for code agreement
- Category agreement ≥ 80% between coders
- Regular calibration sessions throughout analysis
- Documentation of disagreements and resolutions

**Measurement Process**:
1. Sample 10% of cases for independent coding by all team members
2. Calculate agreement statistics using appropriate measures
3. Discuss disagreements and refine coding protocols
4. Re-test reliability after protocol refinements
5. Document reliability results and improvement actions
```

### Credibility and Trustworthiness
```markdown
**Credibility Measures**:
- Prolonged engagement with data and domain
- Persistent observation and detailed analysis
- Triangulation with multiple data sources and methods
- Member checking with stakeholders and experts

**Transferability Measures**:
- Thick description of context and conditions
- Detailed documentation of methodology and process
- Clear articulation of scope and limitations
- Comparison with similar contexts and applications

**Dependability Measures**:
- Detailed audit trail of analysis decisions
- Documentation of methodology evolution and changes
- External audit of analysis process and quality
- Consistency checks across team members and time

**Confirmability Measures**:
- Clear linkage between findings and data
- Documentation of researcher bias and assumptions
- External validation of interpretations and conclusions
- Transparency in analysis process and decision-making
```

---

## Deliverables and Documentation

### Primary Deliverables
1. **Comprehensive Analysis Report** (50-100 pages)
   - Executive summary with key findings and recommendations
   - Detailed methodology and process documentation
   - Complete findings with supporting evidence and examples
   - Actionable recommendations with implementation guidance

2. **Coded Dataset and Analysis Files**
   - Complete coded dataset with all codes and categories
   - Analysis files and query results from qualitative software
   - Coding memos and analytical documentation
   - Quality assurance and reliability assessment results

3. **Visual Analysis Outputs**
   - Relationship maps and causal models
   - Pattern visualization and frequency charts
   - Thematic maps and conceptual frameworks
   - Process flows and decision trees

### Supporting Documentation
1. **Methodology Documentation**
   - Detailed process descriptions and protocols
   - Quality assurance procedures and standards
   - Team roles and responsibilities
   - Timeline and milestone tracking

2. **Quality Assurance Reports**
   - Inter-coder reliability assessment results
   - Validation and verification documentation
   - Peer review feedback and responses
   - Credibility and trustworthiness evidence

3. **Implementation Guidance**
   - Recommendation prioritization and rationale
   - Implementation roadmaps and timelines
   - Resource requirements and capability needs
   - Risk assessment and mitigation strategies

---

## Code Examples and Tools

### Qualitative Analysis Code Framework
```python
# Qualitative Error Analysis Framework
import pandas as pd
import numpy as np
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import seaborn as sns
from itertools import combinations

class QualitativeErrorAnalyzer:
    """
    Comprehensive framework for qualitative error analysis using 
    open coding and axial coding methodologies.
    """
    
    def __init__(self):
        self.error_cases = []
        self.codes = defaultdict(list)
        self.categories = {}
        self.relationships = defaultdict(list)
        self.themes = {}
        
    def load_error_cases(self, cases_data):
        """Load error cases for analysis."""
        self.error_cases = cases_data
        print(f"Loaded {len(self.error_cases)} error cases for analysis")
        
    def conduct_open_coding(self, case_id, codes_applied):
        """Apply open coding to individual cases."""
        
        # Store codes for each case
        for code in codes_applied:
            self.codes[code].append(case_id)
            
        # Update case with applied codes
        for case in self.error_cases:
            if case['id'] == case_id:
                case['open_codes'] = codes_applied
                break
                
    def develop_categories(self, code_category_mapping):
        """Develop categories from open codes."""
        
        self.categories = code_category_mapping
        
        # Apply categories to cases
        for case in self.error_cases:
            case_categories = set()
            for code in case.get('open_codes', []):
                for category, codes in self.categories.items():
                    if code in codes:
                        case_categories.add(category)
            case['categories'] = list(case_categories)
            
    def conduct_axial_coding(self, core_phenomenon, causal_conditions, 
                           contextual_conditions, intervening_conditions,
                           action_strategies, consequences):
        """Implement axial coding analysis."""
        
        axial_framework = {
            'core_phenomenon': core_phenomenon,
            'causal_conditions': causal_conditions,
            'contextual_conditions': contextual_conditions,
            'intervening_conditions': intervening_conditions,
            'action_strategies': action_strategies,
            'consequences': consequences
        }
        
        # Apply axial coding to cases
        for case in self.error_cases:
            case['axial_coding'] = self._apply_axial_framework(case, axial_framework)
            
        return axial_framework
        
    def _apply_axial_framework(self, case, framework):
        """Apply axial coding framework to individual case."""
        
        case_axial = {}
        case_categories = set(case.get('categories', []))
        
        # Check for core phenomenon
        if framework['core_phenomenon'] in case_categories:
            case_axial['has_core_phenomenon'] = True
            
            # Analyze conditions and consequences
            case_axial['causal_conditions'] = [
                cond for cond in framework['causal_conditions'] 
                if cond in case_categories
            ]
            case_axial['contextual_conditions'] = [
                cond for cond in framework['contextual_conditions']
                if cond in case_categories
            ]
            case_axial['intervening_conditions'] = [
                cond for cond in framework['intervening_conditions']
                if cond in case_categories
            ]
            case_axial['consequences'] = [
                cons for cons in framework['consequences']
                if cons in case_categories
            ]
        else:
            case_axial['has_core_phenomenon'] = False
            
        return case_axial
        
    def analyze_patterns(self):
        """Analyze patterns in coded data."""
        
        pattern_analysis = {}
        
        # Code frequency analysis
        code_frequencies = {}
        for code, cases in self.codes.items():
            code_frequencies[code] = len(cases)
            
        pattern_analysis['code_frequencies'] = code_frequencies
        
        # Category frequency analysis
        category_frequencies = defaultdict(int)
        for case in self.error_cases:
            for category in case.get('categories', []):
                category_frequencies[category] += 1
                
        pattern_analysis['category_frequencies'] = dict(category_frequencies)
        
        # Co-occurrence analysis
        cooccurrence_matrix = self._calculate_cooccurrence()
        pattern_analysis['cooccurrence_matrix'] = cooccurrence_matrix
        
        # Axial coding pattern analysis
        axial_patterns = self._analyze_axial_patterns()
        pattern_analysis['axial_patterns'] = axial_patterns
        
        return pattern_analysis
        
    def _calculate_cooccurrence(self):
        """Calculate co-occurrence matrix for categories."""
        
        categories = list(self.categories.keys())
        cooccurrence = defaultdict(lambda: defaultdict(int))
        
        for case in self.error_cases:
            case_categories = case.get('categories', [])
            
            # Calculate co-occurrences
            for cat1, cat2 in combinations(case_categories, 2):
                cooccurrence[cat1][cat2] += 1
                cooccurrence[cat2][cat1] += 1
                
        return dict(cooccurrence)
        
    def _analyze_axial_patterns(self):
        """Analyze patterns in axial coding results."""
        
        axial_patterns = {}
        
        # Core phenomenon frequency
        core_phenomenon_cases = [
            case for case in self.error_cases
            if case.get('axial_coding', {}).get('has_core_phenomenon', False)
        ]
        
        axial_patterns['core_phenomenon_frequency'] = len(core_phenomenon_cases)
        
        # Condition analysis
        condition_frequencies = defaultdict(int)
        for case in core_phenomenon_cases:
            axial_data = case.get('axial_coding', {})
            
            for cond in axial_data.get('causal_conditions', []):
                condition_frequencies[f"causal_{cond}"] += 1
            for cond in axial_data.get('contextual_conditions', []):
                condition_frequencies[f"contextual_{cond}"] += 1
            for cond in axial_data.get('intervening_conditions', []):
                condition_frequencies[f"intervening_{cond}"] += 1
                
        axial_patterns['condition_frequencies'] = dict(condition_frequencies)
        
        return axial_patterns
        
    def generate_insights(self, pattern_analysis):
        """Generate insights from pattern analysis."""
        
        insights = {}
        
        # Top patterns
        top_codes = sorted(
            pattern_analysis['code_frequencies'].items(),
            key=lambda x: x[1], reverse=True
        )[:10]
        
        top_categories = sorted(
            pattern_analysis['category_frequencies'].items(),
            key=lambda x: x[1], reverse=True
        )[:10]
        
        insights['top_error_patterns'] = {
            'codes': top_codes,
            'categories': top_categories
        }
        
        # Strong co-occurrences
        cooccurrence = pattern_analysis['cooccurrence_matrix']
        strong_cooccurrences = []
        
        for cat1, cat2_dict in cooccurrence.items():
            for cat2, count in cat2_dict.items():
                if count >= 5:  # Threshold for strong co-occurrence
                    strong_cooccurrences.append((cat1, cat2, count))
                    
        strong_cooccurrences.sort(key=lambda x: x[2], reverse=True)
        insights['strong_cooccurrences'] = strong_cooccurrences[:10]
        
        # Axial coding insights
        axial_patterns = pattern_analysis['axial_patterns']
        insights['axial_insights'] = {
            'core_phenomenon_prevalence': axial_patterns['core_phenomenon_frequency'],
            'key_conditions': sorted(
                axial_patterns['condition_frequencies'].items(),
                key=lambda x: x[1], reverse=True
            )[:10]
        }
        
        return insights
        
    def create_visualizations(self, pattern_analysis):
        """Create visualizations for pattern analysis."""
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # Code frequency chart
        codes, frequencies = zip(*sorted(
            pattern_analysis['code_frequencies'].items(),
            key=lambda x: x[1], reverse=True
        )[:15])
        
        axes[0, 0].barh(range(len(codes)), frequencies)
        axes[0, 0].set_yticks(range(len(codes)))
        axes[0, 0].set_yticklabels(codes)
        axes[0, 0].set_title('Top Error Code Frequencies')
        axes[0, 0].set_xlabel('Frequency')
        
        # Category frequency chart
        categories, cat_frequencies = zip(*sorted(
            pattern_analysis['category_frequencies'].items(),
            key=lambda x: x[1], reverse=True
        )[:10])
        
        axes[0, 1].bar(range(len(categories)), cat_frequencies)
        axes[0, 1].set_xticks(range(len(categories)))
        axes[0, 1].set_xticklabels(categories, rotation=45, ha='right')
        axes[0, 1].set_title('Category Frequencies')
        axes[0, 1].set_ylabel('Frequency')
        
        # Co-occurrence heatmap
        cooccurrence = pattern_analysis['cooccurrence_matrix']
        categories = list(cooccurrence.keys())
        
        if categories:
            cooccurrence_matrix = np.zeros((len(categories), len(categories)))
            for i, cat1 in enumerate(categories):
                for j, cat2 in enumerate(categories):
                    cooccurrence_matrix[i, j] = cooccurrence.get(cat1, {}).get(cat2, 0)
            
            sns.heatmap(cooccurrence_matrix, 
                       xticklabels=categories, 
                       yticklabels=categories,
                       ax=axes[1, 0], 
                       cmap='Blues')
            axes[1, 0].set_title('Category Co-occurrence Matrix')
        
        # Axial coding patterns
        axial_patterns = pattern_analysis['axial_patterns']
        if 'condition_frequencies' in axial_patterns:
            conditions, cond_frequencies = zip(*sorted(
                axial_patterns['condition_frequencies'].items(),
                key=lambda x: x[1], reverse=True
            )[:10])
            
            axes[1, 1].barh(range(len(conditions)), cond_frequencies)
            axes[1, 1].set_yticks(range(len(conditions)))
            axes[1, 1].set_yticklabels(conditions)
            axes[1, 1].set_title('Axial Coding Condition Frequencies')
            axes[1, 1].set_xlabel('Frequency')
        
        plt.tight_layout()
        return fig
        
    def generate_report(self, insights, output_path):
        """Generate comprehensive analysis report."""
        
        report_content = f"""
# Qualitative Error Analysis Report

## Executive Summary

This report presents the results of a comprehensive qualitative error analysis 
conducted using open coding and axial coding methodologies. The analysis 
examined {len(self.error_cases)} error cases to identify patterns, root causes, 
and improvement opportunities.

## Key Findings

### Top Error Patterns
{self._format_top_patterns(insights['top_error_patterns'])}

### Strong Co-occurrences
{self._format_cooccurrences(insights['strong_cooccurrences'])}

### Axial Coding Insights
{self._format_axial_insights(insights['axial_insights'])}

## Detailed Analysis

### Open Coding Results
- Total codes identified: {len(self.codes)}
- Total categories developed: {len(self.categories)}
- Average codes per case: {np.mean([len(case.get('open_codes', [])) for case in self.error_cases]):.2f}

### Axial Coding Results
- Cases with core phenomenon: {insights['axial_insights']['core_phenomenon_prevalence']}
- Percentage with core phenomenon: {insights['axial_insights']['core_phenomenon_prevalence'] / len(self.error_cases) * 100:.1f}%

## Recommendations

Based on the qualitative analysis findings, the following recommendations are proposed:

1. **Address Top Error Patterns**: Focus improvement efforts on the most frequent error patterns identified
2. **Investigate Co-occurrences**: Examine strong co-occurrence patterns for systemic issues
3. **Target Causal Conditions**: Address the most frequent causal conditions identified through axial coding
4. **Implement Monitoring**: Establish ongoing monitoring for identified patterns and conditions

## Methodology

This analysis followed established qualitative research methodologies:
- Open coding for initial pattern identification
- Axial coding for relationship analysis
- Systematic pattern analysis and validation
- Multi-analyst approach for reliability

## Quality Assurance

- Inter-coder reliability achieved: [To be filled based on actual analysis]
- Validation methods applied: Member checking, triangulation, peer review
- Quality standards met: Credibility, transferability, dependability, confirmability
        """
        
        with open(output_path, 'w') as f:
            f.write(report_content)
            
        print(f"Comprehensive report generated: {output_path}")
        
    def _format_top_patterns(self, top_patterns):
        """Format top patterns for report."""
        
        formatted = "#### Top Error Codes:\n"
        for code, frequency in top_patterns['codes'][:5]:
            formatted += f"- {code}: {frequency} occurrences\n"
            
        formatted += "\n#### Top Error Categories:\n"
        for category, frequency in top_patterns['categories'][:5]:
            formatted += f"- {category}: {frequency} occurrences\n"
            
        return formatted
        
    def _format_cooccurrences(self, cooccurrences):
        """Format co-occurrences for report."""
        
        formatted = ""
        for cat1, cat2, count in cooccurrences[:5]:
            formatted += f"- {cat1} + {cat2}: {count} co-occurrences\n"
            
        return formatted
        
    def _format_axial_insights(self, axial_insights):
        """Format axial insights for report."""
        
        formatted = f"Core phenomenon prevalence: {axial_insights['core_phenomenon_prevalence']} cases\n\n"
        formatted += "Key conditions:\n"
        
        for condition, frequency in axial_insights['key_conditions'][:5]:
            formatted += f"- {condition}: {frequency} occurrences\n"
            
        return formatted

# Example usage
if __name__ == "__main__":
    # Initialize analyzer
    analyzer = QualitativeErrorAnalyzer()
    
    # Example error cases (in practice, load from your data)
    example_cases = [
        {
            'id': 'case_001',
            'description': 'AI misclassified medical image due to poor contrast',
            'context': 'Emergency department, night shift',
            'severity': 'high'
        },
        # Add more cases...
    ]
    
    # Load cases
    analyzer.load_error_cases(example_cases)
    
    # Conduct analysis (example workflow)
    # analyzer.conduct_open_coding('case_001', ['image_quality', 'contrast_issue', 'misclassification'])
    # analyzer.develop_categories({'technical_issues': ['image_quality', 'contrast_issue']})
    # analyzer.conduct_axial_coding(...)
    
    print("Qualitative Error Analysis Framework Ready for Use")
```

---

## Best Practices and Optimization

### Coding Best Practices
1. **Stay Close to Data**: Use descriptive codes that reflect actual data content
2. **Maintain Consistency**: Establish and follow consistent coding protocols
3. **Document Decisions**: Keep detailed memos explaining coding rationale
4. **Regular Calibration**: Conduct frequent team discussions to maintain alignment
5. **Iterative Refinement**: Continuously refine codes and categories based on new insights

### Quality Optimization
1. **Multiple Perspectives**: Include diverse team members with different expertise
2. **Systematic Validation**: Use multiple validation methods for robust findings
3. **Transparent Process**: Document all decisions and changes for audit trail
4. **External Review**: Seek independent validation from external experts
5. **Continuous Improvement**: Learn from each analysis to improve future work

### Efficiency Strategies
1. **Tool Utilization**: Leverage qualitative analysis software for efficiency
2. **Parallel Processing**: Conduct some analysis activities in parallel
3. **Template Usage**: Develop templates for common analysis components
4. **Automation**: Automate routine tasks where possible
5. **Knowledge Management**: Build organizational capability for future analyses

---

## Troubleshooting Common Issues

### Low Inter-Coder Reliability
**Symptoms**: Cohen's Kappa < 0.70, high disagreement between coders
**Solutions**:
- Conduct additional training on coding protocols
- Refine code definitions and inclusion criteria
- Increase frequency of calibration sessions
- Consider reducing number of codes or categories

### Overwhelming Code Proliferation
**Symptoms**: Too many codes, difficulty in pattern identification
**Solutions**:
- Implement hierarchical coding structure
- Consolidate similar codes under broader categories
- Focus on most frequent and significant codes
- Use constant comparative method for code refinement

### Insufficient Pattern Emergence
**Symptoms**: Few clear patterns, weak relationships between categories
**Solutions**:
- Increase sample size for analysis
- Ensure adequate diversity in error cases
- Conduct deeper analysis of existing codes
- Consider alternative analytical approaches

### Stakeholder Disagreement with Findings
**Symptoms**: Domain experts question analysis results
**Solutions**:
- Conduct member checking with broader stakeholder group
- Provide more detailed evidence and examples
- Revisit analysis with stakeholder input
- Consider alternative interpretations and perspectives

---

## Integration with Other Methodologies

### Quantitative Analysis Integration
- Use qualitative findings to inform quantitative analysis design
- Validate qualitative insights with statistical analysis
- Combine qualitative depth with quantitative breadth
- Triangulate findings across methodological approaches

### LLM-as-Judge Integration
- Use qualitative insights to design evaluation prompts
- Validate LLM-as-Judge results with qualitative analysis
- Combine automated evaluation with qualitative understanding
- Iterate between qualitative insights and automated evaluation

### Continuous Improvement Integration
- Use qualitative analysis for root cause identification
- Inform improvement strategy design with qualitative insights
- Monitor improvement effectiveness through ongoing qualitative analysis
- Adapt improvement approaches based on qualitative feedback

This comprehensive template provides everything needed to conduct rigorous, systematic qualitative error analysis that generates actionable insights and drives meaningful improvements in AI evaluation quality.

