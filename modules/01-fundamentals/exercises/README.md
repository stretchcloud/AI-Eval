# Module 1 Exercises: Fundamentals of AI Evaluation

This contains hands-on exercises designed to reinforce the key concepts from Module 1. Each exercise includes practical implementation tasks, working code examples, and detailed solutions.

## Exercise Overview

### [Exercise 1: Three Gulfs Analysis](./01-three-gulfs-analysis.md)
**Objective**: Apply the Three Gulfs Model to analyze a real LLM application scenario
**Skills**: Gap identification, systematic analysis, bridging strategy development
**Time**: 45-60 minutes

### [Exercise 2: AMI Lifecycle Implementation](./02-ami-lifecycle-implementation.md)
**Objective**: Implement a complete Analyze-Measure-Improve cycle for an email processing system
**Skills**: Qualitative analysis, metric design, improvement implementation
**Time**: 90-120 minutes

### [Exercise 3: Evaluation Strategy Design](./03-evaluation-strategy-design.md)
**Objective**: Design a comprehensive evaluation strategy for a new LLM application
**Skills**: Strategic planning, stakeholder alignment, framework integration
**Time**: 60-75 minutes

## Prerequisites

- Completion of Module 1 core content
- Python 3.8+ with pandas, numpy, matplotlib
- Basic understanding of LLM applications
- Familiarity with evaluation concepts

## Setup Instructions

1. **Environment Setup**:
   ```bash
   pip install pandas numpy matplotlib seaborn jupyter
   ```

2. **Data Download**:
   ```bash
   # Sample datasets are included in each exercise directory
   # No additional downloads required
   ```

3. **Verification**:
   ```python
   import pandas as pd
   import numpy as np
   import matplotlib.pyplot as plt
   print("Environment ready for Module 1 exercises!")
   ```

## Exercise Structure

Each exercise follows a consistent structure:

- **Scenario Description**: Real-world context and challenges
- **Learning Objectives**: Specific skills and knowledge to be gained
- **Step-by-Step Instructions**: Detailed guidance through the exercise
- **Code Templates**: Starting code with TODO sections
- **Solution Files**: Complete implementations with explanations
- **Reflection Questions**: Critical thinking prompts
- **Extension Activities**: Advanced challenges for deeper learning

## Assessment Criteria

Exercises are designed for self-assessment using these criteria:

- **Conceptual Understanding**: Correct application of frameworks and models
- **Implementation Quality**: Working code that follows best practices
- **Analysis Depth**: Thorough investigation of problems and solutions
- **Strategic Thinking**: Ability to connect tactical work to strategic objectives

## Getting Help

If you encounter difficulties:

1. **Review Module Content**: Revisit relevant sections in Module 1
2. **Check Solution Files**: Compare your approach with provided solutions
3. **Discussion Forums**: Engage with the community (if available)
4. **Office Hours**: Attend virtual office hours (if available)

## Next Steps

After completing these exercises:

- **Module 2**: Apply these foundations to systematic error analysis
- **Module 3**: Extend to automated evaluation systems
- **Real Projects**: Apply frameworks to your own LLM applications

## Exercise Completion Checklist

- [ ] Exercise 1: Three Gulfs Analysis completed
- [ ] Exercise 2: AMI Lifecycle Implementation completed  
- [ ] Exercise 3: Evaluation Strategy Design completed
- [ ] All reflection questions answered
- [ ] Code solutions tested and working
- [ ] Ready to proceed to Module 2

---
